\chapter{Algorithms and software}
\section{Quicksort}

Quicksort pseudocode (shown in Lst. \ref{lst:PseudoQuickSort}) is based on description from \emph{Introduction to Algorithms} \cite{Cormen2009}.

\begin{lstlisting}[basicstyle=\ttfamily, caption={Sequential Quicksort pseudocode}, label={lst:PseudoQuickSort}]

QUICKSORT(A, p, r)
	if p < r
	q = PARTITION(A, p, r)
	QUICKSORT(A, p, q - 1)
  QUICKSORT(A, q + 1, r)
	
PARTITION(A, p, r)
	x = A[r]
	i = p - 1
  for j = p to r - 1
		if A[j] <= x
			i = i + 1
			exchange A[i] with A[j]
	exchange A[i + 1] with A[r]
	return i + 1
\end{lstlisting}


\clearpage
\section{K-means clustering}
k-means, otherwise commonly know as Lloyd's algorithm, is an unsupervised machine learning algorithm which is used to process a data set into clusters.
They represent a geometric shape with a mass center, a centroid.
Each of the clusters has its own centroid which is the sum of points divided by number of total points. 

The algorithm is an iterative process which repeats until it reaches a convergence point or exceeds the limit (sometimes it does not converge).
Each of the iterations updates the centroids to produce better clusters.
The iteration involves these steps:
\begin{enumerate}
	\item Sum up points in each cluster.
	\item Divide each sum by the number of points in respective cluster.
	\item Reassign all points to a closest centroid, distance is calculated through Euclidean distance function.
	\item Repeat until locations stabilize.
\end{enumerate}

In the following subsections 3 implementations of centroid recalculation algorithm will be presented. Each of the them is injected into k-means algorithm (Lst. \ref{lst:KMeans}) during performance benchmarking.

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={K-means centroid computation}, label={lst:KMeans}]
//For clarity
using DataSet = System.Collections.Immutable.ImmutableList<System.Collections.Immutable.ImmutableList<double>>;

public static DataSet ComputeCentroids(Func<DataSet, DataSet> updateCentroids, DataSet centroids,
  int rowLength)
{
  for (var i = 0; i <= 1000; i++)
  {
    var (newCentroids, error) = GetNewCentroidsAndError(updateCentroids, rowLength, centroids);

    if (error < 1e-9)
      return newCentroids;
    
    centroids = newCentroids;
  }

  return centroids;
}

private static (DataSet, double) GetNewCentroidsAndError(Func<DataSet, DataSet> updateCentroids, int rowLength, DataSet centroids)
{
  var newCentroids = updateCentroids(centroids).SortCentroids(rowLength);
  var error = double.MaxValue;

  if (centroids.Count == newCentroids.Count)
    error = centroids.Select((t, j) => DistanceTo(t, newCentroids[j])).Sum();

  return (newCentroids, error);
}


private static DataSet SortCentroids(this DataSet result, int RowLength)
  => result.Sort((a, b) =>
  {
    for (var i = 0; i < RowLength; i++)
      if (a[i] != b[i])
        return a[i].CompareTo(b[i]);
    return 0;
  });


public static ImmutableList<double> GetNearestCentroid(DataSet centroids, ImmutableList<double> center) 
  => centroids.Aggregate((centroid1, centroid2) => 
    centroid2.DistanceTo(center) < centroid1.DistanceTo(center)
      ? centroid2
      : centroid1);

private static double DistanceTo(this ImmutableList<double> @from, ImmutableList<double> to)
{
  var results = 0.0;
  for (var i = 0; i < @from.Count; i++)
    results += Math.Pow(@from[i] - to[i], 2.0);
  return results;

}
\end{lstlisting}

\subsubsection{Sequential implementation}

\emph{UpdateCentroids} evaluates each cluster and reassigns centroids to newly calculated centers in two steps. In the first one \emph{GroupBy} function is used to aggregate the points using the \emph{GetNearestCentroid} function as a key. In the next one, each point grouping is used to calculate new centers for each given point. This step is achieved via local accumulator in \emph{Aggregate} function and collection combining in \emph{Zip} function which threads centroids and accumulator sequences. Finally, each center is determined through dividing with number of points in the cluster (Lst. \ref{lst:SeqKMeans}).


\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Sequential k-means algorithm}, label={lst:SeqKMeans}]
private Func<DataSet, DataSet> UpdateCentroids()
  => centroids =>
    Source
      .GroupBy(row => KMeans.GetNearestCentroid(centroids, row))
      .Select(CalculateCenter)
      .ToImmutableList();

private ImmutableList<double> CalculateCenter(IGrouping<ImmutableList<double>, ImmutableList<double>> points) 
  => points
    .Aggregate(new double[RowLength], (acc, item) => acc.Zip(item, (a, b) => a + b).ToArray())
    .Select(items => items / points.Count())
    .ToImmutableList();
\end{lstlisting}

\subsubsection{Parallel implementation}

This  implementation uses PLINQ (TODO: Add reference) which easily transforms sequential LINQ query into a parallel one with 2 lines of code.
This was enabled by using \emph{Aggregate}, LINQ's equivalent of functional sequence transforming function: \emph{Seq.Fold}. Force parallelism execution mode is used to make sure that PLINQ internal mechanism won't transform the query into a sequential one.

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Parallel k-means algorithm}, label={lst:ParKMeans}]
private Func<DataSet, DataSet> UpdateCentroids()
  => centroids =>
    Source
      .AsParallel()
      .WithExecutionMode(ParallelExecutionMode.ForceParallelism)
      .GroupBy(u => KMeans.GetNearestCentroid(centroids, u))
      .Select(CalculateCenter)
      .ToImmutableList();

private ImmutableList<double> CalculateCenter(IGrouping<ImmutableList<double>, ImmutableList<double>> points)
  => points
    .Aggregate(new double[RowLength], (acc, item) => acc.Zip(item, (a, b) => a + b).ToArray())
    .Select(items => items / points.Count())
    .ToImmutableList();
\end{lstlisting}

\subsubsection{Parallel implementation with data partitioner}

To further boost the parallel implementation, data partitioner was used to load balance the data between threads (TODO: Add reference) (Lst. \ref{lst:PartParKMeans}). 

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Parallel k-means algorithm with partitioner}, label={lst:PartParKMeans}]
private Func<DataSet, DataSet> UpdateCentroids()
  => centroids 
    => Partitioner
    .Create(Source, loadalBalance: true)
    .AsParallel()
    .WithExecutionMode(ParallelExecutionMode.ForceParallelism)
    .GroupBy(u => KMeans.GetNearestCentroid(centroids, u))
    .Select(CalculateCenter)
    .ToImmutableList();

private ImmutableList<double> CalculateCenter(IGrouping<ImmutableList<double>, ImmutableList<double>> points) 
  => points
    .Aggregate(new double[RowLength], (acc, item) => acc.Zip(item, (a, b) => a + b).ToArray())
    .Select(items => items / points.Count())
    .ToImmutableList();
\end{lstlisting}

\clearpage
\section{Mandelbrot}

Mandelbrot set images are made by sampling complex numbers and testing for each sample point whether the orbit of the critical point z = 0 under iteration of the quadratic map remains bounded (eq.\ref{eq:Mandelbrot}) \cite{MandelbrotExplorer}. Images of the Mandelbrot set display an elaborate boundary that reveals complex structure arising from the application of simple rules. It's one of the best-known examples of mathematical visualization. It was named in the tribute of a pioneer of fractal geometry, Benoit Mandelbrot, by Adrien Douady. \cite{Douady}

\begin{equation}
\centering 
z_n + 1 = z_n^2 + c
\label{eq:Mandelbrot}
\end{equation}

In the following subsections 3 implementations of Mandelbrot set drawing algorithms will be presented. Each of the them is injected into bitmap generating code (Lst. \ref{lst:Bitmap}) during performance benchmarking. Example visualization made during the experiments is presented on Fig. \ref{fig:MandelbrotVis}.

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Mandelbrot bitmap generation}, label={lst:Bitmap}]
public static Bitmap DrawMandelbrotBitmap(Action<BitmapData, byte[]> mandelbrotDrawingStrategy, int rows, int columns)
{
  var bitmap = new Bitmap(rows, columns, PixelFormat.Format24bppRgb);
  var bitmapData = LockBitmap(bitmap);
  var allPixels = new byte[bitmapData.Stride * bitmap.Height];
  var firstPixel = bitmapData.Scan0;
  Marshal.Copy(firstPixel, allPixels, 0, allPixels.Length);

  mandelbrotDrawingStrategy(bitmapData, allPixels);

  Marshal.Copy(allPixels, 0, firstPixel, allPixels.Length);
  UnlockBitmap(bitmap, bitmapData);

  return (Bitmap)bitmap.Clone();
}

private static BitmapData LockBitmap(Bitmap bitmap) 
  => bitmap.LockBits(new Rectangle(0,
      0,
      bitmap.Width,
      bitmap.Height),
    ImageLockMode.ReadWrite,
    PixelFormat.Format24bppRgb);

private static void UnlockBitmap(Bitmap bitmap, BitmapData bitmapData) 
  => bitmap.UnlockBits(bitmapData);

\end{lstlisting}

\begin{figure}[!ht]
	\centering
		\includegraphics[width = 0.5\textwidth]{figures04/MandelbrotVis.png}
	\caption{Mandelbrot set visualization}
	\label{fig:MandelbrotVis}
\end{figure}

\pagebreak
\subsubsection{Sequential implementation}
This implementation consists of two nested loops. The outer one iterates over the columns of the bitmap while the inner one iterates over its rows. 
Pixel coordinates are translated into real and imaginary parts of a complex number by using the \emph{ComputeColumn} and \emph{ComputeRow} functions. Afterwards \emph{BelongsToMandelbrot} function checks if the number is part of the Mandelbrot set (Lst. \ref{lst:SeqMandelbrot}).

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Sequential Mandelbrot algorithm}, label={lst:SeqMandelbrot}]
private Action<BitmapData, byte[]> DrawingStrategy()
  => (bitmapData, pixels) =>
  {
    for (var column = 0; column < Columns; column++) 
    {
      for (var row = 0; row < Rows; row++) 
      {
        var x = Center.ComputeRow(row, Width, Columns); 
        var y = Center.ComputeColumn(column, Height, Rows); 
        var c = new ComplexNumber(x, y);
        var color = BelongsToMandelbrot(c, 100) ? Color.Black : Color.White; 
        var offset = (column * bitmapData.Stride) + (3 * row);
        pixels.WriteColors(offset, color);
      }
    }
  };

private static bool BelongsToMandelbrot(ComplexNumber number, int iterations)
{
  var zNumber = new ComplexNumber(0.0f, 0.0f);
  var accumulator = 0;
  while (accumulator < iterations && zNumber.Magnitude() < 2.0)
  {
    zNumber = zNumber.MultiplyWith(zNumber).AddTo(number);
    ++accumulator;
  }

  return accumulator == iterations;
}
\end{lstlisting}

\subsubsection{Parallel implementation}
Parallel version was implemented using Fork/Join (TODO: Add reference) pattern. TPL (TODO: Add Reference) enables us to easily apply this pattern with multiple parallelization constructs, in this case the \emph{Parallel.For} replacement for sequential loops. (Lst. \ref{lst:ParMandelbrot})

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Parallel Mandelbrot algorithm}, label={lst:ParMandelbrot}]
private Action<BitmapData, byte[]> DrawingStrategy()
  => (bitmapData, pixels) =>
    Parallel.For(0, Columns - 1, column =>
    {
      for (var row = 0; row < Rows; row++)
      {
        var x = Center.ComputeRow(row, Width, Columns);
        var y = Center.ComputeColumn(column, Height, Rows);
        var c = new ComplexNumber(x, y);
        var color = BelongsToMandelbrot(c, 100) ? Color.Black : Color.White;
        var offset = (column * bitmapData.Stride) + (3 * row);
        pixels.WriteColors(offset, color);
      }
    });

private static bool BelongsToMandelbrot(ComplexNumber number, int iterations)
{
  var zNumber = new ComplexNumber(0.0f, 0.0f);
  var accumulator = 0;
  while (accumulator < iterations && zNumber.Magnitude() < 2.0)
  {
    zNumber = zNumber.MultiplyWith(zNumber).AddTo(number);
    ++accumulator;
  }
  return accumulator == iterations;
}
\end{lstlisting}

\subsubsection{Double parallel implementation}
This version replaced both sequential loops with TPL's \emph{Parallel.For} construct. It will be useful to examine how oversaturation impacts the algorithm performance (Lst. \ref{lst:DoubleParMandelbrot})

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Double parallel Mandelbrot algorithm}, label={lst:DoubleParMandelbrot}]
private Action<BitmapData, byte[]> DrawingStrategy()
  => (bitmapData, pixels) =>
    Parallel.For(0, Columns - 1, column =>
    {
      Parallel.For(0, Rows - 1, row =>
      {
        var x = Center.ComputeRow(row, Width, Columns);
        var y = Center.ComputeColumn(column, Height, Rows);
        var c = new ComplexNumber(x, y);
        var color = BelongsToMandelbrot(c, 100) ? Color.Black : Color.White;
        var offset = (column * bitmapData.Stride) + (3 * row);
        pixels.WriteColors(offset, color);
      });
    });

private static bool BelongsToMandelbrot(ComplexNumber number, int iterations)
{
  var zNumber = new ComplexNumber(0.0f, 0.0f);
  var accumulator = 0;
  while (accumulator < iterations && zNumber.Magnitude() < 2.0)
  {
    zNumber = zNumber.MultiplyWith(zNumber).AddTo(number);
    ++accumulator;
  }
  return accumulator == iterations;
}
\end{lstlisting}

\subsubsection{Parallel implementation using value types}

In some cases .NET's Garbage Collector can be the bottleneck of the application. Reference type objects are allocated on the heap and are very cheap to use as a function argument since only the pointer is copied. These objects though have a memory overhead and may heavily tax the GC which will stop the execution of the program until cleanup is done. Contrary to that, value type objects are allocated on the stack and will never cause GC to pause the program. This version uses \emph{ComplexNumberStruct} objects which are identical to previous versions except they are value type instead of reference type.  (Lst. \ref{lst:ParStructMandelbrot})

\begin{lstlisting}[language={[sharp]c}, style=sharpcstyle, caption={Parallel Mandelbrot algorithm using value types}, label={lst:ParStructMandelbrot}]

private Action<BitmapData, byte[]> DrawingStrategy()
  => (bitmapData, pixels) =>
    Parallel.For(0, Columns - 1, column =>
    {
      for (var row = 0; row < Rows; row++)
      {
        var x = Center.ComputeRow(row, Width, Columns);
        var y = Center.ComputeColumn(column, Height, Rows);
        var c = new ComplexNumberStruct(x, y);
        var color = BelongsToMandelbrot(c, 100) ? Color.Black : Color.White;
        var offset = (column * bitmapData.Stride) + (3 * row);
        pixels.WriteColors(offset, color);
      }
    });


private static bool BelongsToMandelbrot(ComplexNumberStruct number, int iterations)
{
  var zNumber = new ComplexNumberStruct(0.0f, 0.0f);
  var accumulator = 0;
  while (accumulator < iterations && zNumber.Magnitude() < 2.0)
  {
    zNumber = zNumber.MultiplyWith(zNumber).AddTo(number);
    ++accumulator;
  }
  return accumulator == iterations;
}

\end{lstlisting}

